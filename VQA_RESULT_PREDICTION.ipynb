{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxDMAe31lAZQqJhTc/d61o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/btripura/VQA_MODEL/blob/main/VQA_RESULT_PREDICTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5GFkarfGVyC"
      },
      "outputs": [],
      "source": [
        "!pip install wget\n",
        "!pip install datasets==1.17.0 nltk==3.5 pandas==1.3.5 Pillow scikit-learn==0.23.2 torch==1.12.0 transformers==4.15.0 dvc==2.9.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --pre allennlp-models"
      ],
      "metadata": {
        "id": "UzkeIAIdBFj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "from google.colab import files\n",
        "from IPython.display import Image\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "yj50f8atA9M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "1Fg1KtDJGkhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb=\"gdrive/MyDrive\"\n",
        "from allennlp_models.pretrained import load_predictor\n",
        "predictor = load_predictor(\"vqa-vilbert\")"
      ],
      "metadata": {
        "id": "zuYiTihAGrZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "TdPKbpLXGaJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array,array_to_img"
      ],
      "metadata": {
        "id": "arIytINEKMtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "import cv2, numpy as np\n",
        "import time\n",
        "import math as mth\n",
        "from PIL import Image\n",
        "import random\n",
        "import argparse\n",
        "from hmac import trans_36\n",
        "from shutil import move\n",
        "from socket import CAN_BCM_RX_CHANGED\n",
        "from cv2 import detail_AffineBasedEstimator\n",
        "from keras.models import Sequential\n",
        "from keras import initializers\n",
        "from keras.initializers import normal, identity\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.recurrent import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "\n",
        "from IPython.display import Image,display\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "import PIL.Image\n",
        "import io\n",
        "from transformers import VisualBertForQuestionAnswering, BertTokenizerFast\n",
        "import torch"
      ],
      "metadata": {
        "id": "-oNfom4ESXOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "delta=10\n",
        "\n",
        "\n",
        "#Image Dimensions\n",
        "H=224\n",
        "W=224\n",
        "\n",
        "X = 0\n",
        "Y = 0\n",
        "\n",
        "\n",
        "st_x=0\n",
        "e_x=W\n",
        "st_y=0\n",
        "e_y=H\n",
        "\n",
        "xval=0\n",
        "yval=0"
      ],
      "metadata": {
        "id": "8_u_1zQ-Svk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_q=[]\n",
        "with open('train_questions.txt','r') as fp:\n",
        "  for line in fp:\n",
        "    x=line[:-1]\n",
        "    train_q.append(x)\n",
        "#train_q = np.load('gdrive/MyDrive/train_ques_tokenizer.npy')\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_q)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('\\n--- Converting questions to bags of words...')\n",
        "train_X_seqs = tokenizer.texts_to_matrix(train_q)"
      ],
      "metadata": {
        "id": "sNG3JfHeNkKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fef50bb-fe8f-49aa-aa3a-dc364db87a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Converting questions to bags of words...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_image(image_path):\n",
        "       im = PIL.Image.open(image_path)\n",
        "       im=im.resize((224,224))\n",
        "       im=np.array(im)\n",
        "       return im"
      ],
      "metadata": {
        "id": "SNGWGy-pJe88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ims=[]\n",
        "test_ims.append(load_and_process_image('img4.jpg'))"
      ],
      "metadata": {
        "id": "NnyEeHO6PM-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_ques='What is color of bus'\n",
        "test_q=[]\n",
        "test_q.append(my_ques)\n",
        "\n",
        "# We add one because the Keras Tokenizer reserves index 0 and never uses it.\n",
        "test_X_seqs=tokenizer.texts_to_matrix(test_q)"
      ],
      "metadata": {
        "id": "ybkyiwQGOQCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def transform(image,x_val,y_val):\n",
        "    global X\n",
        "    global Y\n",
        "    X=x_val\n",
        "    Y=y_val\n",
        "    M=np.float32([[1,0,X],[0,1,Y]])\n",
        "    output=cv2.warpAffine(image,M,(224,224))\n",
        "    fdf=[X,Y]\n",
        "    return cropped(output)\n",
        "\n",
        "def cropped(image):\n",
        "        start_x=st_x\n",
        "        start_y=st_y\n",
        "        end_x=e_x\n",
        "        end_y=e_y\n",
        "        values=[X,Y]\n",
        "        if(X<0):\n",
        "           end_x=W+X\n",
        "        if(X>0):\n",
        "           start_x=X\n",
        "        if(Y<0):\n",
        "           end_y=H+Y\n",
        "        if(Y>0):\n",
        "           start_y=Y\n",
        "        crop=image[start_y:end_y,start_x:end_x]\n",
        "        resized=cv2.resize(crop,(W,H),interpolation=cv2.INTER_NEAREST)\n",
        "        return resized"
      ],
      "metadata": {
        "id": "1Od6OHPLTv7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image,ques):\n",
        "    URL='temp.jpg'\n",
        "    preds = predictor.predict(URL, ques)\n",
        "    best_prob, best_answer = max(zip(preds[\"probs\"], preds[\"tokens\"]), key=lambda x: x[0])\n",
        "    return (best_answer,(best_prob/100))"
      ],
      "metadata": {
        "id": "F5bfUqk9UCoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step(state,ques,action):\n",
        "    global xval\n",
        "    global yval\n",
        "    xval=X\n",
        "    yval=Y\n",
        "    if action==0:\n",
        "        xval+=delta\n",
        "    elif action==1:\n",
        "        xval-=delta\n",
        "    elif action==2:\n",
        "        yval+=delta\n",
        "    elif action==3:\n",
        "        yval-=delta\n",
        "    elif action==4:\n",
        "      pass\n",
        "    vad=[xval,yval]\n",
        "    new_image=transform(state[0],xval,yval)\n",
        "    image=array_to_img(new_image)\n",
        "    image.save('temp.jpg')\n",
        "    predict_ans,new_conf=predict(image,ques)\n",
        "    new_image=img_to_array(new_image)\n",
        "    return (new_image,predict_ans,new_conf)"
      ],
      "metadata": {
        "id": "O0ek5YRIVVvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('gdrive/MyDrive/model_final.h5')"
      ],
      "metadata": {
        "id": "yxFGe8ycVe2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_action(state):\n",
        "    q_values=model.predict([np.array([state[0]]),np.array([state[1]])]) #Exploitation\n",
        "    max_Q = np.argmax(q_values[0])\n",
        "    action = max_Q\n",
        "\n",
        "    return action"
      ],
      "metadata": {
        "id": "qQfirlZeWeuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset():\n",
        "  global X\n",
        "  global Y\n",
        "  global st_x\n",
        "  global st_x\n",
        "  global e_x\n",
        "  global st_y\n",
        "  global e_y\n",
        "  global xval\n",
        "  global yval\n",
        "  xval=0\n",
        "  yval=0\n",
        "  X=0\n",
        "  Y=0\n",
        "  st_x=0\n",
        "  e_x=224\n",
        "  st_y=0\n",
        "  e_y=224"
      ],
      "metadata": {
        "id": "jgjUUY5Mk3Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reset()\n",
        "pred_answers=[]\n",
        "pred_without_rein=[]\n",
        "correct_answers=[]\n",
        "answers=[]\n",
        "confidence=[]\n",
        "img=test_ims[0]\n",
        "ques=test_X_seqs[0]\n",
        "state=[img,ques]\n",
        "for j in range(5):\n",
        "    action=get_action(state)\n",
        "    new_img,ans,conf=step(state,my_ques,action)\n",
        "    answers.append(ans)\n",
        "    confidence.append(conf)\n",
        "    state=[new_img,ques]\n",
        "pred_ans=answers[confidence.index(max(confidence))]\n",
        "print('Question---',my_ques)\n",
        "print('Answer-----',pred_ans)\n"
      ],
      "metadata": {
        "id": "PaEjpexunkar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "def compute_metrics(pred_vals,correct_vals):\n",
        "  acc= accuracy_score(correct_vals, pred_vals)\n",
        "  f1= f1_score(correct_vals, pred_vals, average='macro')\n",
        "  return (acc,f1)"
      ],
      "metadata": {
        "id": "rhW4AFBVRT3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_answers=[]\n",
        "pred_without_rein=[]\n",
        "for i in range(len(test_ims)):\n",
        "  reset()\n",
        "  answers=[]\n",
        "  confidence=[]\n",
        "  img=test_ims[i]\n",
        "  ques=test_q[i]\n",
        "  state=[img,test_X_seqs[i]]\n",
        "  pred,con=predict(img,ques)\n",
        "  pred_without_rein.append(pred)\n",
        "  for j in range(steps):\n",
        "    action=get_action(state)\n",
        "    new_img,ans,conf=step(state,ques,action)\n",
        "    answers.append(ans)\n",
        "    confidence.append(conf)\n",
        "    state=[new_img,test_X_seqs[i]]\n",
        "  pred_ans=answers[confidence.index(max(confidence))]\n",
        "  pred_answers.append(pred_ans)\n",
        "  correct_answers.append(test_a[i])\n",
        "accuracy_without_rein,f1_without_rein=compute_metrics(pred_without_rein,correct_answers)\n",
        "accuracy,f1=compute_metrics(pred_answers,correct_answers)\n",
        "print('Accuracy without Reinforcement Learning-----',accuracy_without_rein*100)\n",
        "print('Accuracy with Reinforcement Learning-----',accuracy*100)\n",
        "\n"
      ],
      "metadata": {
        "id": "zEvK-g32S07c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
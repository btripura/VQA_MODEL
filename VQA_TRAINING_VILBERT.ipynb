{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrD5D9q5GbQHyhbKrA2aB9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/btripura/VQA_MODEL/blob/main/VQA_TRAINING_VILBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5GFkarfGVyC"
      },
      "outputs": [],
      "source": [
        "!pip install wget\n",
        "!pip install datasets==1.17.0 nltk==3.5 pandas==1.3.5 Pillow scikit-learn==0.23.2 torch==1.12.0 transformers==4.15.0 dvc==2.9.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --pre allennlp-models"
      ],
      "metadata": {
        "id": "UzkeIAIdBFj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "from google.colab import files\n",
        "from IPython.display import Image\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "yj50f8atA9M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "TdPKbpLXGaJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "1Fg1KtDJGkhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb=\"gdrive/MyDrive\"\n",
        "from allennlp_models.pretrained import load_predictor\n",
        "predictor = load_predictor(\"vqa-vilbert\")"
      ],
      "metadata": {
        "id": "zuYiTihAGrZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array,array_to_img"
      ],
      "metadata": {
        "id": "arIytINEKMtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "import cv2, numpy as np\n",
        "import time\n",
        "import math as mth\n",
        "from PIL import Image\n",
        "import random\n",
        "import argparse\n",
        "from hmac import trans_36\n",
        "from shutil import move\n",
        "from socket import CAN_BCM_RX_CHANGED\n",
        "from cv2 import detail_AffineBasedEstimator\n",
        "from keras.models import Sequential\n",
        "from keras import initializers\n",
        "from keras.initializers import normal, identity\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.recurrent import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "\n",
        "from IPython.display import Image,display\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "import PIL.Image\n",
        "import io\n",
        "from transformers import VisualBertForQuestionAnswering, BertTokenizerFast\n",
        "import torch"
      ],
      "metadata": {
        "id": "-oNfom4ESXOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_q=[]\n",
        "with open('train_questions.txt','r') as fp:\n",
        "  for line in fp:\n",
        "    x=line[:-1]\n",
        "    train_q.append(x)\n",
        "\n",
        "train_a=[]\n",
        "with open('train_answers.txt','r') as fp:\n",
        "  for line in fp:\n",
        "    x=line[:-1]\n",
        "    train_a.append(x)\n",
        "\n",
        "train_id=[]\n",
        "with open('train_image_ids.txt','r') as fp:\n",
        "  for line in fp:\n",
        "    x=line[:-1]\n",
        "    train_id.append(x)"
      ],
      "metadata": {
        "id": "sNG3JfHeNkKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_image(image_path):\n",
        "       im = PIL.Image.open(image_path)\n",
        "       im=im.resize((224,224))\n",
        "       im=np.array(im)\n",
        "       return im\n",
        "def read_images():\n",
        "        ims=[]\n",
        "        for i in range(70000):\n",
        "          image_name=train_id[i].strip()\n",
        "          ims.append(load_and_process_image(os.path.join(imdb, \"train_images\", image_name)))\n",
        "        return ims\n",
        "\n",
        "train_ims=read_images()\n",
        "print(len(train_ims))\n",
        "img_shape=train_ims[0].shape\n",
        "print(img_shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "EmGWHox4OKXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_q)\n",
        "\n",
        "# We add one because the Keras Tokenizer reserves index 0 and never uses it.\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "print('\\n--- Converting questions to bags of words...')\n",
        "train_X_seqs = tokenizer.texts_to_matrix(train_q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybkyiwQGOQCQ",
        "outputId": "56e44c61-2e70-443d-d112-040d356d1aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Converting questions to bags of words...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_actions=5\n",
        "observing_episodes=20\n",
        "# How many steps can run the agent until finding one object\n",
        "number_of_steps = 10\n",
        "# Boolean to indicate if you want to use the two databases, or just one\n",
        "episodes = 70000\n",
        "gamma = 0.90\n",
        "epsilon_current_value = 1\n",
        "epsilon_initial_value=1\n",
        "epsilon_final_value=0.0001\n",
        "batch_size = 100\n",
        "replay_memory = 5000\n",
        "transitions=deque()\n",
        "\n",
        "number_of_actions = 5\n",
        "delta=10\n",
        "\n",
        "\n",
        "#Image Dimensions\n",
        "H=224\n",
        "W=224\n",
        "\n",
        "X = 0\n",
        "Y = 0\n",
        "\n",
        "\n",
        "st_x=0\n",
        "e_x=W\n",
        "st_y=0\n",
        "e_y=H\n",
        "\n",
        "xval=0\n",
        "yval=0"
      ],
      "metadata": {
        "id": "8_u_1zQ-Svk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def transform(image,x_val,y_val):\n",
        "    print('Transforming Image')\n",
        "    global X\n",
        "    global Y\n",
        "    X=x_val\n",
        "    Y=y_val\n",
        "    M=np.float32([[1,0,X],[0,1,Y]])\n",
        "    output=cv2.warpAffine(image,M,(224,224))\n",
        "    fdf=[X,Y]\n",
        "    return cropped(output)\n",
        "\n",
        "def cropped(image):\n",
        "        start_x=st_x\n",
        "        start_y=st_y\n",
        "        end_x=e_x\n",
        "        end_y=e_y\n",
        "        #print('cropping\\n')\n",
        "        values=[X,Y]\n",
        "        #print(values)\n",
        "        if(X<0):\n",
        "           end_x=W+X\n",
        "        if(X>0):\n",
        "           start_x=X\n",
        "        if(Y<0):\n",
        "           end_y=H+Y\n",
        "        if(Y>0):\n",
        "           start_y=Y\n",
        "        crop=image[start_y:end_y,start_x:end_x]\n",
        "        resized=cv2.resize(crop,(W,H),interpolation=cv2.INTER_NEAREST)\n",
        "        #print('after crop')\n",
        "        #cv2_imshow(resized)\n",
        "        return resized"
      ],
      "metadata": {
        "id": "1Od6OHPLTv7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image,ques):\n",
        "    print('Predicting Answer')\n",
        "    URL='temp.jpg'\n",
        "    preds = predictor.predict(URL, ques)\n",
        "    best_prob, best_answer = max(zip(preds[\"probs\"], preds[\"tokens\"]), key=lambda x: x[0])\n",
        "    print(f\"p({best_answer}) = {best_prob:.2%}\")\n",
        "    print(\"answer:--\",best_answer)\n",
        "    print(\"Conf---\",best_prob)\n",
        "    return (best_answer,(best_prob/100))"
      ],
      "metadata": {
        "id": "F5bfUqk9UCoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reward(image,ques,ans,prev_conf):\n",
        "    print('Calculating Reward')\n",
        "    image=array_to_img(image)\n",
        "    #print(image.size)\n",
        "    image.save('temp.jpg')\n",
        "    #print('saved')\n",
        "    predict_ans,new_conf=predict(image,ques)\n",
        "    #print('Question: ',ques)\n",
        "    #print('Answer: ', predict_ans)\n",
        "    if(ans==predict_ans):\n",
        "      return (new_conf-prev_conf,new_conf)\n",
        "    else:\n",
        "       return (-1,0)"
      ],
      "metadata": {
        "id": "vz7tnomqUTNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step(state,ques,ans,conf,action):\n",
        "    #print('action taking---',action)\n",
        "    print('Performing action')\n",
        "    global xval\n",
        "    global yval\n",
        "    xval=X\n",
        "    yval=Y\n",
        "    if action==0:\n",
        "        xval+=delta\n",
        "    elif action==1:\n",
        "        xval-=delta\n",
        "    elif action==2:\n",
        "        yval+=delta\n",
        "    elif action==3:\n",
        "        yval-=delta\n",
        "    elif action==4:\n",
        "      pass\n",
        "    #print('IN step:')\n",
        "    vad=[xval,yval]\n",
        "    #print(vad)\n",
        "    new_image=transform(state[0],xval,yval)\n",
        "\n",
        "    reward,new_conf=get_reward(new_image,ques,ans,conf)\n",
        "    new_image=img_to_array(new_image)\n",
        "    return (new_image,reward,new_conf)"
      ],
      "metadata": {
        "id": "O0ek5YRIVVvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Multiply,Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "def create_model(im_shape, vocab_size, num_actions):\n",
        "  print('creating model---\\n')\n",
        "  im_input = Input(shape=im_shape)\n",
        "  x1 = Conv2D(8, 3, padding='same')(im_input)\n",
        "  x1 = MaxPooling2D()(x1)\n",
        "  x1 = Conv2D(16, 3, padding='same')(x1)\n",
        "  x1 = MaxPooling2D()(x1)\n",
        "  x1 = Flatten()(x1)\n",
        "  x1 = Dense(1000, activation='relu')(x1)\n",
        "  # The question network\n",
        "  q_input = Input(shape=(vocab_size,))\n",
        "  embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(q_input)\n",
        "  x2 = LSTM(256)(embedded_question)\n",
        "  x2 = Dense(1000, activation='relu')(x2)\n",
        "  # Merge -> output\n",
        "  out = Multiply()([x1, x2])\n",
        "  out = Dense(1000, activation='relu')(out)\n",
        "  out = Dense(num_actions, activation='softmax')(out)\n",
        "  model = Model(inputs=[im_input, q_input], outputs=out)\n",
        "  model.compile(Adam(lr=5e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "T6BR-G-RVZ52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=create_model(img_shape,vocab_size,num_actions)\n",
        "#model=load_model('gdrive/MyDrive/model_trained.h5')"
      ],
      "metadata": {
        "id": "yxFGe8ycVe2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remember(state,action,next_state,reward):      #This is the function to store our experiences\n",
        "    print('Remembering state')\n",
        "    global transitions\n",
        "    transitions.append([state,action,next_state,reward])\n",
        "    #print(len(transitions))\n",
        "    if len(transitions) > replay_memory:\n",
        "      transitions.popleft()"
      ],
      "metadata": {
        "id": "9SoX9tJRVjnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_action(state):\n",
        "    print('Getting action')\n",
        "    x=random.random()\n",
        "    if x < epsilon_current_value:\n",
        "        #print('random--\\n')\n",
        "        action=random.choice([0,1,2,3,4])\n",
        "        #print(action)\n",
        "\n",
        "    else:\n",
        "        q_values=model.predict([np.array([state[0]]),np.array([state[1]])]) #Exploitation\n",
        "        max_Q = np.argmax(q_values[0])\n",
        "        action = max_Q\n",
        "        #print('not random',action)\n",
        "\n",
        "    return action"
      ],
      "metadata": {
        "id": "qQfirlZeWeuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "#checkpoint = ModelCheckpoint('model.h5', save_best_only=True)\n",
        "def update_policy():\n",
        "    print('Updating policy---\\n')\n",
        "    global transitions\n",
        "    transitions=random.sample(transitions,batch_size)\n",
        "    #print(len(transitions))\n",
        "    train_x_ims=[]\n",
        "    train_x_ques=[]\n",
        "    targets = np.zeros((batch_size,5))\n",
        "    train_x_ims=np.array([transitions[id][0][0] for id in range(batch_size)])\n",
        "    train_x_ques=np.array([transitions[id][0][1] for id in range(batch_size)])\n",
        "    targets=model.predict([train_x_ims,train_x_ques])\n",
        "    train_x_next_ims=np.array([transitions[id][2][0] for id in range(batch_size)])\n",
        "    train_x_next_ques=np.array([transitions[id][2][1] for id in range(batch_size)])\n",
        "    Q_sa=model.predict([train_x_next_ims,train_x_next_ques])\n",
        "    for i in range(0,batch_size):\n",
        "      action=transitions[i][1] #This is action\n",
        "      reward=transitions[i][3] #reward at state due to action\n",
        "      targets[i, action] = reward + np.asarray(gamma) * np.max(Q_sa[i])\n",
        "    model.fit([train_x_ims,train_x_ques], targets,epochs=50,) #Training the model"
      ],
      "metadata": {
        "id": "ZJtQ40HuWhsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset():\n",
        "  global X\n",
        "  global Y\n",
        "  global st_x\n",
        "  global st_x\n",
        "  global e_x\n",
        "  global st_y\n",
        "  global e_y\n",
        "  global xval\n",
        "  global yval\n",
        "  xval=0\n",
        "  yval=0\n",
        "  X=0\n",
        "  Y=0\n",
        "  st_x=0\n",
        "  e_x=224\n",
        "  st_y=0\n",
        "  e_y=224"
      ],
      "metadata": {
        "id": "jgjUUY5Mk3Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for episode in range(episodes):\n",
        "    state=[train_ims[episode],train_X_seqs[episode]]\n",
        "    episode_reward=0\n",
        "    conf=0\n",
        "    print('Episode: ',episode)\n",
        "    reset()\n",
        "    for i in range(number_of_steps):\n",
        "        print(\"Step: \",i)\n",
        "        action=get_action(state)\n",
        "        new_image,reward,new_conf=step(state,train_q[episode],train_a[episode],conf,action)\n",
        "        next_state=[new_image,train_X_seqs[episode]]\n",
        "        conf=new_conf\n",
        "        print(\"Episode Going On.\"+\"\\n\"+\"Action taken:\"+'\\t',action)\n",
        "        remember(state,action,next_state,reward)\n",
        "        state=next_state\n",
        "        episode_reward+=reward\n",
        "    print(\"Episode_reward:{}\".format(episode_reward))\n",
        "    print('Current Epsilon Value:',epsilon_current_value)\n",
        "    epsilon_current_value=epsilon_current_value-(epsilon_initial_value-epsilon_final_value)/1000\n",
        "    print(\"Episode Ended\")\n",
        "    if (episode+1)%observing_episodes==0 and episode!=0:\n",
        "        update_policy()\n",
        "        model.save('model_2_{}.h5'.format(episode))\n",
        "        #files.download('model_2_{}.h5'.format(episode))"
      ],
      "metadata": {
        "id": "DOyCiKxDWmxo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}